## transPPMP
![](file:///C:\Users\User\AppData\Local\Temp\ksohtml40964\wps1.jpg)

transPPMP模型原理概述：对于n条样本。

1、截取突变位点上下文序列。截取上下各100位氨基酸，数据维度（n,201）

2、使用表示学习将序列中字符映射到表示空间。具体地，使用在大量蛋白质序列上预训练的ESM蛋白质语言模型，将它的最后一层输出作为每个氨基酸的表示。最后一层输出为1280维，数据维度（n,201,1280）。

3、全连接层降低氨基酸的特征维度，加上位置编码信息输入transformer模块编码。

4、对于Encoder的上下文序列特征矩阵（n,201,256）输出，仅取突变位点的信息（n,256）

5、融合其他人工提取的特征，做预测。

我的理解是：transPPMP模型的深度学习模块=表示学习+深度学习网络，这是个通用的架构。

transPPMP模型深度学习网络使用transformer，可以学习氨基酸之间的相互作用信息。由于使用移码和无义突变数据集，能学习到致病移码和无义突变中氨基酸的相互作用。

换成别的突变数据集应该也是同理。


## 《Evaluation of in silico pathogenicity prediction tools for the classification of small in-frame indels》[1]

这篇文章构建了gnomA、ClinVar上的测试集和DDD（the Deciphering Developmental Disorders）额外测试集，评测了9种预测框内插入缺失突变的方法。其中额外测试集中的样本不太可能被以前工具用做训练集。在测试集上的实验表明这些预测方法框内插入缺失突变的AUC（根据推荐的阈值）达到了标准的错义突变预测工具的水平（0.81–0.96），但在额外测试集上AUC均有下降（0.64–0.87）。这个结论是对比他们之前对错义突变工具的类似评估。但是对于较新的错义突变预测工具（meta - Predictor Revel和ClinPred），还是比不上。

**可以使用他的额外测试集（70 个致病性和 81 个良性）作为一个独立测试集。**对于所有测试集的数据，文章提供了各个工具的预测结果。

## 《SHINE: Protein Language Model based Prediction of Pathogenicity for Short Inframe Insertion and Deletion Variants》[2]

SHINE使用在大规模数据上预训练的无监督蛋白质语言模型提取特征，其中使用在蛋白质序列上预训练的ESM-1b和在multiple protein sequence alignments(MSAs)上训练的MSA transformer分别提取蛋白质序列上下文特征和结构特征，预训练模型能够迁移知识以弥补框内插入缺失突变数据的不足，使得提取的特征包含输入蛋白质生物学特性信息的潜在表示。将提取的特征用主成分分析后，使用机器学习分类。

SHINE的一个构造独立测试集的亮点是：它认为以往的研究的致病indels仅从几百个已知的疾病基因中选取，而良性indels的来源广泛，所以这些方法倾向于根据疾病基因预测致病性。而SHINE的作者构造了不同来源的同一组基因的变异，作为独立测试集。

## 《MetaRNN: differentiating rare pathogenic and rare benign missense SNVs and InDels using deep learning》[3]

这篇文章关注于罕见错义突变和罕见框内插入缺失突变。我主要关注了数据处理部分。另一个对我目前工作相关的一点是：它对于错义突变和框内indel用相同的框架处理，并且处理过后具有相似的分布。我的理解是他使用的方法对这两个突变特征提取的空间里，两个分布能够相似。进一步，可能存在一个特征空间，能使得两个突变分布相似。这个结果让我对错义到框内indel的迁移性有一定信心。